
---
# T4 - GPUs y CUDA

[Atrás](../README.md)

---
## Arquitectura
### Modelos de CPU
- **Modelo secuencial / tradicional**
	- Se ejecuta paso a paso.
- **SIMT - Single Instruction, Multiple Threads**
	- Se divide el trabajo en varios hilos (pocos hilos)
- **SIMD - Single Instruction , Multiple Data**
	- Se opera con vectores pequeños en un solo ciclo.
### Modelo de GPU
#### Física
1. **GPU - Graphics Processing Unit**
	- Dispone de una memoria global (VRAM)
2. **GPG - Graphics Processing Cluster**
3. **TPC - Texture Processing Cluster**
4. **SMs - Streaming Multiprocessors**
	- Tiene una memoria compartida más rapida (Shared Memory).
	- Dispone de un warp scheduler.
5. **Cuda Cores**
	- Tiene una memoria más rapida (Register File).
#### Lógica
1. Device (GPU)
	- Se refiere a la GPU.
	- Ejecuta los kernels.
2. Malla de bloques (Grid)
	- Representa el problema en su totalidad.
	- Es el conjunto de bloques definido al lanzar el kernel.
3. Bloque de hilos (Thread Block)
	- Unidad programable más pequeña.
	- Conjunto de hilos (max. 1024) que se define al lanzar un kernel.
	- Pueden trabajar en 1D, 2D y 3D. (Cuidado con el max. hilos)
1. Warp
2. Hilo

3. **Hilo**
	- El hilo es la unidad más pequeña de ejecución.
	- Cada hilo se ejecutará en un núcleo CUDA
4. **Warp**
	- Son grupos de 32 hilos.
	- Unidad ejecutable más pequeña.
	- Todos sus hilos se ejecutan de manera sincronizada.
	- No todos los hilos de un warp ejecutan instrucciones.
5. **Bloque de hilo (Thread block)**
	- Unidad programable más pequeña.
		- Conjunto de hilos (max. 1024) que se define al lanzar un kernel.
		- Pueden trabajar en 1D, 2D y 3D. (Cuidado con el max. hilos)
	- Se asignan a un Streaming Multiprocessor (SM) para ejecutarse.
		- Cada SM tiene su memoria compartida.
		- Cada SM tiene un Warp Scheduler que organiza los Warps.
6. **Malla de bloques (Grid)**
	- Conjunto de bloques definido al lanzar el kernel.
	- CUDA balancea la carga entre los distintos SM.
	- Representa el problema total en la GPU.
7. GPU (device)
	- Se conoce como `device`
	- Ejecuta kernels en sus SM.
	- Tiene una memoria global para todos los SM.
