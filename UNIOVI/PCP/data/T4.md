
---
# T4 - GPUs y CUDA

[Atrás](../README.md)

---
## Arquitectura CPU y GPU
### Modelos de CPU
- **Modelo secuencial / tradicional**
	- Se ejecuta paso a paso.
- **SIMT - Single Instruction, Multiple Threads**
	- Se divide el trabajo en varios hilos (pocos hilos)
- **SIMD - Single Instruction , Multiple Data**
	- Se opera con vectores pequeños en un solo ciclo.
### Modelo de GPU
#### Física
1. **GPU - Graphics Processing Unit**
	- Dispone de una memoria global (VRAM)
2. **GPG - Graphics Processing Cluster**
3. **TPC - Texture Processing Cluster**
4. **SMs - Streaming Multiprocessors**
	- Tiene una memoria compartida más rapida (Shared Memory).
	- Dispone de un warp scheduler.
5. **Cuda Cores**
	- Tiene una memoria más rapida (Register File).
#### Lógica
1. **Device (GPU)**
	- Se refiere a la GPU.
	- Ejecuta los kernels.
2. **Malla de bloques (Grid)**
	- Representa el problema en su totalidad.
	- Es el conjunto de bloques definido al lanzar el kernel.
3. **Bloque de hilos (Thread Block)**
	- Unidad programable más pequeña.
	- Conjunto de hilos (max. 1024) que se define al lanzar un kernel.
	- Pueden trabajar en 1D, 2D y 3D. (Cuidado con el max. hilos)
	- Los bloques se asignan a un SM para que los ejecute.
4. **Warp**
	- Unidad ejecutable más pequeña.
	- Agrupación de 32 hilos gestinados por el Warp Scheduler.
	- Todos sus hilos se ejecutan de manera sincronizada.
	- No todos los hilos de un warp ejecutan instrucciones.
5. **Hilo**
	- El hilo es la unidad más pequeña de ejecución.
	- Cada hilo se ejecutará en un núcleo CUDA

---
## Nomenclatura de Matrices

![](../assets/Nomenclatura_matrices.svg)

---
## CUDA - Kernels
### Definición
- Define el código que se ejecutará en cada hilo.
- Los hilos se agrupan en bloques. Cada hilo tiene:
	- Un ID de bloque.
	- Un ID de hilo dentro del bloque.
- Estos IDs se pueden acceder con variables intrínsecas, pudiendo:
	- Variar el flujo de ejecución (con `if`).
	- Acceder a distintos datos.

```c++
// Definición
__global__ void nombre_kernel(...) { ... }

// Llamada
nombre_kernel<<<numero_bloques, hilos_por_bloque>>>(...)
```

### Ejecución de kernels
- La ejecución es asíncrona con respecto a la CPU:
	- La CPU llama al kernel y sigue ejecutando sin esperar a que termine.
	- Para esperar podemos usar la función: `cudaDeviceSynchronize()`
- Los bloques se ejecutan sin sincronización entre ellos.
	- Cada bloque se asigna a un SM.
	- Los bloques se dividen en warps de 32 hilos.
- Los hilos de un bloque:
	- Pueden sincronizarse con la barrera: `__syncthreads()`
	- Pueden compartir datos con la Shared Memory. Se define como: `__shared__`
- Se pueden definir variables en la GPU con `__device__`
	- Accesible por los hilos de todos los bloques.

### Dimensiones
#### 1D - Dimension X
```c++
#define TPB 3
#define NB(size) (size + TPB - 1) / TPB

// Tenemos un vector V de tamaño size
__global__ void kernel_1D(int *V, int size)
{
	int i = blockIdx.x * blockDim.x + threadIdx.x; // ID de hilo en grid.

	if(i < size) { ... } // Comprobamos que estamos dentro de los márgenes.
}

kernel_1D<<< NB(size) , TPB >>>(V, size);
```

![](../assets/Cuda_1D.svg)
#### 2D - Dimensiones X e Y
```c++
#define TPB_X = 3
#define TPB_Y = 2

#define TPB() dim3(TPB_X, TPB_Y)
#define NB(m, n) dim3( (m + TPB_X - 1) / TPB_X , (n + TPB_Y - 1) / TPB_Y)

// Tenemos una matriz M en column major de dimensiones nxm
__global__ void kernel_2D(int *M, int m, int n)
{
	int j = blockIdx.x * blockDim.x + threadIdx.x; // Columna del hilo en grid
	int i = blockIdx.y * blockDim.y + threadIdx.y; // Fila del hilo en grid

	if (i < m && j < n) { ... } // Comprobamos que estamos dentro de los márgenes.
}

kernel_2D<<< NB(m, n) , TPB() >>>(M, m, n);
```

![](../assets/Cuda_2D.svg)
 
---
## CUDA - Errores
#### Errores en funciones
```C++
// Simple
if (cudaMemcpy(...) != cudaSuccess) {...}
```

```c++
// Macro
#define CUDAERR(x) do { if((x)!=cudaSuccess) { \
	printf("CUDA error: %s : %s, line %d\n", cudaGetErrorString(x), __FILE__, __LINE__);\
	return EXIT_FAILURE;}} while(0)

// Uso
CUDAERR(cudaMemcpy(...));
```
#### Errores en kernels
```C++
// Simple
kernel<<<...>>>(...);
if (cudaSuccess != cudaGetLastError()) {...}
```

```c++
// Macro
#define CUDACHECK() __getLastCudaError(__FILE__, __LINE__)

inline void __getLastCudaError(const char *file, const int line)
{
	if (cudaSuccess != cudaGetLastError())
	{
		fprintf(stderr, "%s(%i): getLastCudaError() error: (%d) %s.\n",
			file, line, (int)err, cudaGetErrorString(err));
		exit(-1);
	}
}

// Uso
kernel<<<...>>>(...);
CUDACHECK();
```
---
## CUDA - Eventos 

pag 42

---

Organización de Warps
```c++
threadId = (
	threadIdx.x
	+ blockDim.x * threadIdx.y
	+ blockDim.x * blockDim.y * threadIdx.z
)
```

![](../assets/Pasted%20image%2020241203200700.png)

